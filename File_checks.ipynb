{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7657b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618740b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz'\n",
    "\n",
    "model_file = model_url.split('/')[-1]  # Extract \n",
    "if not os.path.isfile(model_file):\n",
    "    urllib.request.urlretrieve(model_url, model_file)\n",
    "\n",
    "if model_file.endswith('.tar.gz'):\n",
    "    tar = tarfile.open(model_file, 'r:gz')\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    print(f\"Extracted {model_file} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd25fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_structure(startpath, depth=3):\n",
    "\n",
    "    prefix = '|   '\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = prefix * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        if level < depth:\n",
    "            subindent = prefix * (level + 1)\n",
    "            for f in files:\n",
    "                print('{}{}'.format(subindent, f))\n",
    "\n",
    "base_model_dir = '/scratch/rk42218/Building_Detection_scratch/exported_models/'\n",
    "print_directory_structure(base_model_dir, depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24723123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e926946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "checkpoint_dir_or_prefix = '/home/rk42218/Building_Detection/garden garden/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index'\n",
    "\n",
    "if os.path.isdir(checkpoint_dir_or_prefix):\n",
    "    checkpoint_prefix = tf.train.latest_checkpoint(checkpoint_dir_or_prefix)\n",
    "else:\n",
    "    checkpoint_prefix = checkpoint_dir_or_prefix\n",
    "\n",
    "try:\n",
    "    reader = tf.train.load_checkpoint(checkpoint_prefix)\n",
    "    variable_shapes = reader.get_variable_to_shape_map()\n",
    "    variable_names = sorted(variable_shapes.keys())\n",
    "    \n",
    "    print(f\"Successfully loaded checkpoint from {checkpoint_prefix}.\")\n",
    "    print(\"Variables and their shapes:\")\n",
    "    for variable_name in variable_names:\n",
    "        print(f\"  {variable_name}: {variable_shapes[variable_name]}\")\n",
    "    print(f\"Total variables: {len(variable_names)}\")\n",
    "\n",
    "except tf.errors.NotFoundError as e:\n",
    "    print(f\"Error loading checkpoint: {e}. Please check the path and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bfc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb92c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "checkpoint_path = '/home/rk42218/Building_Detection/garden garden/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0'\n",
    "variables = tf.train.list_variables(checkpoint_path)\n",
    "\n",
    "for name, shape in variables:\n",
    "    print(f'{name}: {shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd3bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "checkpoint_path = '/home/rk42218/Building_Detection/garden garden/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0'\n",
    "variables = tf.train.list_variables(checkpoint_path)\n",
    "print(variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c55b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafcb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def inspect_checkpoint_tf2(checkpoint_path):\n",
    "    try:\n",
    "        reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "        \n",
    "        variable_shapes = reader.get_variable_to_shape_map()\n",
    "        variable_names = sorted(variable_shapes.keys())\n",
    "        \n",
    "        print(f\"Variables in the checkpoint '{checkpoint_path}':\")\n",
    "        for name in variable_names:\n",
    "            print(f\"  {name}, shape: {variable_shapes[name]}\")\n",
    "        \n",
    "        print(\"\\nCheckpoint inspection completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint '{checkpoint_path}': {e}\")\n",
    "        print(\"This checkpoint may not be compatible with TensorFlow 2.\")\n",
    "\n",
    "checkpoint_prefix = '/home/rk42218/Building_Detection/garden garden/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0'\n",
    "\n",
    "inspect_checkpoint_tf2(checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf202d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52394e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38286c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_classes(image_folder, mask_folder):\n",
    "    image_files = os.listdir(image_folder)\n",
    "    mask_files = os.listdir(mask_folder)\n",
    "\n",
    "    unique_classes = set()\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        unique_classes.update(np.unique(mask))\n",
    "\n",
    "    return unique_classes\n",
    "\n",
    "image_folder = \"/home/rk42218/DATA_SET_1024/chunks_images/1024/\"\n",
    "mask_folder = \"/home/rk42218/DATA_SET_1024/chunks_masks/1024_m/\"\n",
    "\n",
    "unique_classes = count_classes(image_folder, mask_folder)\n",
    "\n",
    "print(\"Number of unique classes:\", len(unique_classes))\n",
    "print(\"Unique classes:\", unique_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b25db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_folder = \"/home/rk42218/DATA_SET_1024/data_split/train/images/\"\n",
    "mask_folder = \"/home/rk42218/DATA_SET_1024/data_split/train/masks/\"\n",
    "\n",
    "def load_data(image_folder, mask_folder):\n",
    "    images = []\n",
    "    masks = []\n",
    "    mismatches = 0  \n",
    "    \n",
    "    image_files = [f for f in os.listdir(image_folder) if f.startswith(\"chunk_\") and (f.endswith(\".jpg\") or f.endswith(\".png\"))]\n",
    "    \n",
    "    progress_bar = tqdm(image_files, desc=\"Loading Images and Masks\", position=0, leave=True)\n",
    "    \n",
    "    for filename in progress_bar:\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        mask_filename = \"mask_\" + filename.split('.')[0] + \".png\"\n",
    "        mask_path = os.path.join(mask_folder, mask_filename)\n",
    "        \n",
    "        if os.path.isfile(mask_path):\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if image is not None and mask is not None:\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                mismatches += 1\n",
    "        else:\n",
    "            mismatches += 1\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    return images, masks, mismatches\n",
    "\n",
    "images, masks, mismatches = load_data(image_folder, mask_folder)\n",
    "print(f\"Loaded {len(images)} images and {len(masks)} masks with {mismatches} mismatches (missing masks or images).\")\n",
    "\n",
    "def check_classes(masks):\n",
    "    unique_classes = set()\n",
    "    for mask in masks:\n",
    "        unique_classes.update(np.unique(mask))\n",
    "    return unique_classes\n",
    "\n",
    "unique_classes = check_classes(masks)\n",
    "print(\"Number of classes in masks:\", len(unique_classes))\n",
    "\n",
    "binary_masks = all(set(np.unique(mask)).issubset({0, 255}) for mask in masks)\n",
    "print(\"Masks are binary.\" if binary_masks else \"Masks are not binary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_record_path = '/home/rk42218/DATA_SET_1024/data_split/train/train.record'\n",
    "\n",
    "def parse_example(example):\n",
    "    example_fmt = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, example_fmt)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(train_record_path)\n",
    "\n",
    "for i, record in enumerate(dataset.take(1)): \n",
    "    parsed_example = parse_example(record.numpy())\n",
    "    print(parsed_example)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
