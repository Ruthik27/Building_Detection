{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c6d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "explicit_packages = [\n",
    "    'tensorflow',\n",
    "    'wandb',\n",
    "    'numpy',\n",
    "    'opencv-python-headless',  \n",
    "    'imgaug'\n",
    "]\n",
    " \n",
    "indirect_packages = [\n",
    "    'h5py',  \n",
    "    'Pillow',  \n",
    "    'matplotlib',  \n",
    "    'scipy',  \n",
    "    'scikit-learn'  \n",
    "]\n",
    " \n",
    "all_packages = explicit_packages + indirect_packages\n",
    " \n",
    "package_versions = {}\n",
    "for package in all_packages:\n",
    "    try:\n",
    "        imported_package = __import__(package)\n",
    "        version = getattr(imported_package, '__version__', 'No version attribute')\n",
    "        package_versions[package] = version\n",
    "    except ImportError:\n",
    "        package_versions[package] = 'Not installed'\n",
    " \n",
    "package_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77722e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def get_system_info():\n",
    "    print(\"--- System Information ---\")\n",
    "    print(\"OS:\", os.uname().sysname, os.uname().release)\n",
    "    print(\"Processor:\", subprocess.check_output(['uname', '-m']).decode().strip())\n",
    "\n",
    "def get_memory_info():\n",
    "    print(\"\\n--- Memory Information ---\")\n",
    "    meminfo = dict((i.split()[0].rstrip(':'),int(i.split()[1])) for i in open('/proc/meminfo').readlines())\n",
    "    total_memory_kb = meminfo['MemTotal']\n",
    "    available_memory_kb = meminfo['MemAvailable']\n",
    "    print(\"Total Memory:\", round(total_memory_kb / (1024.0 ** 2), 2), \"GB\")\n",
    "    print(\"Available Memory:\", round(available_memory_kb / (1024.0 ** 2), 2), \"GB\")\n",
    "\n",
    "def get_gpu_info():\n",
    "    print(\"\\n--- GPU Information ---\")\n",
    "    try:\n",
    "        gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.total,memory.used,memory.free,utilization.gpu,temperature.gpu', '--format=csv,noheader,nounits']).decode().strip().split('\\n')\n",
    "        for i, gpu in enumerate(gpu_info):\n",
    "            print(f\"GPU {i+1}:\")\n",
    "            total_mem, used_mem, free_mem, utilization, temp = gpu.split(', ')\n",
    "            print(\"Memory Total:\", total_mem, \"MB\")\n",
    "            print(\"Memory Used:\", used_mem, \"MB\")\n",
    "            print(\"Memory Free:\", free_mem, \"MB\")\n",
    "            print(\"GPU Utilization:\", utilization, \"%\")\n",
    "            print(\"Temperature:\", temp, \"C\")\n",
    "            print()\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"No NVIDIA GPU available.\")\n",
    "\n",
    "def main():\n",
    "    get_system_info()\n",
    "    get_memory_info()\n",
    "    get_gpu_info()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd064a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ff6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  \n",
    "\n",
    "if tf.__version__.startswith('2.'):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f58b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ac284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "#import cpuinfo\n",
    "#import GPUtil\n",
    "\n",
    "def get_system_info():\n",
    "    print(\"--- System Information ---\")\n",
    "    print(\"OS:\", platform.system(), platform.release())\n",
    "    print(\"Processor:\", platform.processor())\n",
    "\n",
    "def get_memory_info():\n",
    "    print(\"\\n--- Memory Information ---\")\n",
    "    svmem = psutil.virtual_memory()\n",
    "    print(\"Total Memory:\", round(svmem.total / (1024.0 ** 3), 2), \"GB\")\n",
    "    print(\"Available Memory:\", round(svmem.available / (1024.0 ** 3), 2), \"GB\")\n",
    "\n",
    "def get_gpu_info():\n",
    "    print(\"\\n--- GPU Information ---\")\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"GPU {i+1}:\")\n",
    "            print(\"Name:\", gpu.name)\n",
    "            print(\"Memory Total:\", gpu.memoryTotal, \"MB\")\n",
    "            print(\"Memory Used:\", gpu.memoryUsed, \"MB\")\n",
    "            print(\"Memory Free:\", gpu.memoryFree, \"MB\")\n",
    "            print(\"GPU Utilization:\", gpu.load * 100, \"%\")\n",
    "            print(\"Temperature:\", gpu.temperature, \"C\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No GPU available.\")\n",
    "\n",
    "def main():\n",
    "    get_system_info()\n",
    "#    get_cpu_info()\n",
    "    get_memory_info()\n",
    "#    get_gpu_info()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1764a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def get_system_info():\n",
    "    print(\"--- System Information ---\")\n",
    "    print(\"OS:\", os.uname().sysname, os.uname().release)\n",
    "    print(\"Processor:\", subprocess.check_output(['uname', '-m']).decode().strip())\n",
    "\n",
    "def get_memory_info():\n",
    "    print(\"\\n--- Memory Information ---\")\n",
    "    meminfo = dict((i.split()[0].rstrip(':'),int(i.split()[1])) for i in open('/proc/meminfo').readlines())\n",
    "    total_memory_kb = meminfo['MemTotal']\n",
    "    available_memory_kb = meminfo['MemAvailable']\n",
    "    print(\"Total Memory:\", round(total_memory_kb / (1024.0 ** 2), 2), \"GB\")\n",
    "    print(\"Available Memory:\", round(available_memory_kb / (1024.0 ** 2), 2), \"GB\")\n",
    "\n",
    "def main():\n",
    "    get_system_info()\n",
    "    get_memory_info()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf3508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ed177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_structure(root_dir, depth=0, max_files=5):\n",
    "    if depth > 0:  \n",
    "        print(\"|  \" * (depth-1) + \"|--\" + os.path.basename(root_dir))\n",
    "\n",
    "    try:\n",
    "        files = os.listdir(root_dir)\n",
    "        for i, file in enumerate(files):\n",
    "            if os.path.isdir(os.path.join(root_dir, file)):\n",
    "                print_directory_structure(os.path.join(root_dir, file), depth + 1, max_files)\n",
    "                if i >= max_files - 1:\n",
    "                    break\n",
    "            elif i < max_files:\n",
    "                print(\"|  \" * depth + \"|--\" + file)  \n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "root_dir = \"../data_split/\"\n",
    "\n",
    "print_directory_structure(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a654124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_data_integrity(dataset_dir):\n",
    "    image_dir = os.path.join(dataset_dir, \"images\")\n",
    "    mask_dir = os.path.join(dataset_dir, \"masks\")\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(\".png\")]\n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith(\".png\")]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        mask_file = f\"mask_{image_file}\"\n",
    "        if mask_file not in mask_files:\n",
    "            print(f\"Missing mask for image: {image_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81616b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_integrity(\"../data_split/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2e9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac41eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_integrity(\"../data_split/val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466781e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ee071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingDataset(utils.Dataset):\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        mask_path = info['mask_path']\n",
    "        mask = skimage.io.imread(mask_path)\n",
    "\n",
    "        print(f\"Original mask shape for image_id {image_id}: {mask.shape}\")\n",
    "\n",
    "        if mask.ndim == 3:\n",
    "            mask = skimage.color.rgb2gray(mask)\n",
    "        \n",
    "        mask = (mask > 0).astype(np.bool)\n",
    "\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "        print(f\"Final mask shape for image_id {image_id}: {mask.shape}\")\n",
    "        class_ids = np.array([1 for _ in range(mask.shape[-1])])\n",
    "        print(f\"Class IDs for image_id {image_id}: {class_ids}\")\n",
    "\n",
    "        return mask, class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb0404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    print(\"Standalone Keras version:\", keras.__version__)\n",
    "except ImportError:\n",
    "    print(\"Keras is integrated within TensorFlow, version:\", tf.keras.__version__)\n",
    "\n",
    "# Check h5py version\n",
    "print(\"h5py version:\", h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e4e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea55681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow can access GPUs.\")\n",
    "else:\n",
    "    print(\"TensorFlow cannot access GPUs.\")\n",
    "\n",
    "print(\"Built with CUDA: \", tf.test.is_built_with_cuda())\n",
    "print(\"CUDA GPUs available: \", tf.config.list_physical_devices('CUDA'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc734c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"Default GPU Device:\", tf.test.gpu_device_name())\n",
    "else:\n",
    "    print(\"TensorFlow cannot access GPUs.\")\n",
    "\n",
    "import os\n",
    "print(\"CUDA version (from environment variable):\", os.getenv(\"CUDA_VERSION\"))\n",
    "print(\"cuDNN version (from environment variable):\", os.getenv(\"CUDNN_VERSION\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2612f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41044741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cuda_version = subprocess.run(['nvcc', '--version'], text=True, capture_output=True)\n",
    "print(cuda_version.stdout)\n",
    "\n",
    "cudnn_version_cmd = \"cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\"\n",
    "cudnn_version = subprocess.run(cudnn_version_cmd, text=True, capture_output=True, shell=True)\n",
    "print(cudnn_version.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a07d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "import subprocess\n",
    "\n",
    "cuda_version = subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"utf-8\")\n",
    "print(\"CUDA version:\", cuda_version.split()[-2])\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b46f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b769f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import os\n",
    "\n",
    "def load_mask(image_id, mask_dir):\n",
    "    mask_path = os.path.join(mask_dir, f'{image_id}.png')  \n",
    "    mask = imread(mask_path)\n",
    "    \n",
    "    unique_classes = np.unique(mask)[1:]  \n",
    "\n",
    "    class_counts = {class_id: np.sum(mask == class_id) for class_id in unique_classes}\n",
    "    \n",
    "    return mask, class_counts\n",
    "\n",
    "def print_mask_metrics(mask, class_counts):\n",
    "    total_pixels = mask.size\n",
    "    print(f\"Total pixels in the mask: {total_pixels}\")\n",
    "    \n",
    "    for class_id, count in class_counts.items():\n",
    "        percentage = (count / total_pixels) * 100\n",
    "        print(f\"Class ID {class_id} covers {count} pixels, which is {percentage:.2f}% of the image.\")\n",
    "\n",
    "image_id = 'mask_chunk_19456_57856' \n",
    "mask_dir = '../data_split/train/masks/'  \n",
    "\n",
    "mask, class_counts = load_mask(image_id, mask_dir)\n",
    "print_mask_metrics(mask, class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09eb21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505adf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import random\n",
    "\n",
    "def analyze_mask_images(mask_dir, num_samples=50):\n",
    "    analysis_results = []\n",
    "\n",
    "    all_filenames = [f for f in os.listdir(mask_dir) if f.endswith(\".png\")]  \n",
    "\n",
    "    sampled_filenames = random.sample(all_filenames, min(num_samples, len(all_filenames)))\n",
    "\n",
    "    for filename in sampled_filenames:\n",
    "        mask_path = os.path.join(mask_dir, filename)\n",
    "        mask = skimage.io.imread(mask_path)\n",
    "\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        total_pixels = mask.size\n",
    "        result = {\n",
    "            'filename': filename,\n",
    "            'unique_class_ids': unique,\n",
    "            'class_pixel_counts': counts,\n",
    "            'total_pixels': total_pixels\n",
    "        }\n",
    "\n",
    "        percentages = (counts / total_pixels) * 100\n",
    "        result['class_percentages'] = percentages\n",
    "\n",
    "        analysis_results.append(result)\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "mask_dir = '../data_split/train/masks/' \n",
    "\n",
    "results = analyze_mask_images(mask_dir, num_samples=50)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Mask: {result['filename']}\")\n",
    "    for class_id, count, percentage in zip(result['unique_class_ids'], result['class_pixel_counts'], result['class_percentages']):\n",
    "        print(f\"  Class ID {class_id}: {count} pixels, {percentage:.2f}% of the image\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a54681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a798670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/rk42218/Building_Detection/Mask_RCNN/env/lib/python3.7/site-packages/mask_rcnn_extracted/')\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "#import wandb\n",
    "import logging\n",
    "import imgaug.augmenters as iaa\n",
    "from keras.callbacks import Callback\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn import utils\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "import tensorflow as tf\n",
    "\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import imgaug.augmenters as iaa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from mrcnn.model import MaskRCNN  \n",
    "from mrcnn import utils\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sys\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f8a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c05e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_bbox(mask):\n",
    "    \"\"\"Find the bounding box of a mask. Returns an empty list if no object is found.\"\"\"\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    if not np.any(rows) or not np.any(cols):\n",
    "        return [0, 0, 0, 0]  # Or return [] if you prefer\n",
    "    \n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    return [int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)]\n",
    "\n",
    "def create_annotations(image_dir, mask_dir, output_file):\n",
    "    annotations = {'images': []}\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        image_id = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        class_id = 1  \n",
    "\n",
    "        mask_file = f\"mask_{image_id}.png\"  \n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            bbox = find_bbox(mask)\n",
    "\n",
    "            annotations['images'].append({\n",
    "                'file_name': image_file,\n",
    "                'id': image_id,\n",
    "                'annotations': [\n",
    "                    {\n",
    "                        'class_id': class_id,\n",
    "                        'bbox': bbox\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "\n",
    "image_dir = '/home/rk42218/data_split/train/images/'\n",
    "mask_dir = '/home/rk42218/data_split/train/masks'\n",
    "\n",
    "output_file = '/home/rk42218/data_split/train/train_annotations.json'\n",
    "\n",
    "create_annotations(image_dir, mask_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc4c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_bbox(mask):\n",
    "    \"\"\"Find the bounding box of a mask. Returns an empty list if no object is found.\"\"\"\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    if not np.any(rows) or not np.any(cols):\n",
    "        return [0, 0, 0, 0]  # Or return [] if you prefer\n",
    "    \n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    return [int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)]\n",
    "\n",
    "def create_annotations(image_dir, mask_dir, output_file):\n",
    "    annotations = {'images': []}\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        image_id = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        class_id = 1  \n",
    "\n",
    "        mask_file = f\"mask_{image_id}.png\"  \n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            bbox = find_bbox(mask)\n",
    "\n",
    "            annotations['images'].append({\n",
    "                'file_name': image_file,\n",
    "                'id': image_id,\n",
    "                'annotations': [\n",
    "                    {\n",
    "                        'class_id': class_id,\n",
    "                        'bbox': bbox\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "\n",
    "image_dir = '/home/rk42218/data_split/val/images/'\n",
    "mask_dir = '/home/rk42218/data_split/val/masks'\n",
    "\n",
    "output_file = '/home/rk42218/data_split/val/val_annotations.json'\n",
    "\n",
    "create_annotations(image_dir, mask_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0416c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
